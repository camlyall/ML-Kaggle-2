{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron w Pre Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# global\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# classification\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import csv\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "matplotlib.rcParams['backend'] = \"Qt4Agg\"\n",
    "\n",
    "seed = 150389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from files\n",
    "train_df = pd.read_csv(\"training.csv\", delimiter=\",\", header=0)\n",
    "test_df = pd.read_csv(\"testing.csv\", delimiter=\",\", header=0)\n",
    "confidence_df = pd.read_csv(\"annotation_confidence.csv\", delimiter=\",\", header=0)\n",
    "additional_df = pd.read_csv(\"additional_training.csv\", delimiter=\",\", header=0)\n",
    "proportions_df = pd.read_csv(\"test_proportions.csv\", delimiter=\",\", header=None, dtype=\"unicode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the training and additional data\n",
    "all_df = pd.concat([train_df, additional_df], ignore_index=True)\n",
    "\n",
    "# get lists of confident and unconfident IDs\n",
    "unconfident_list = confidence_df[confidence_df.confidence != 1]['ID'].tolist()\n",
    "confident_list = confidence_df[confidence_df.confidence == 1]['ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = []\n",
    "with open('../annotation_confidence.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=\",\")\n",
    "    #confidence={int(row['ID'])-1:int(float(row['confidence'])) for row in reader} #float(row['confidence'])\n",
    "    for row in reader:\n",
    "        confidence.append(float(row['confidence']))\n",
    "#confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option1:Fill with [ALL] average"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# update additional data nan values with average values of each column\n",
    "additional_avg = additional_df.mean(axis=0)[1:-1]\n",
    "additional_df = additional_df.fillna(additional_df.mean(axis=0)[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option2:Fill with [Confidence and Prediction] averages\n",
    "- Split data two fold based on confidence and prediction\n",
    "    - Confident prediction 0\n",
    "    - Confident prediction 1\n",
    "    - Unconfident prediction 0\n",
    "    - Unconfident prediction 1\n",
    "- Fill NaN of each with mean\n",
    "- Update the additional dataframe with new data (filled nan values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confident all 0 and 1 prediction averages\n",
    "confident_all_df = all_df[all_df['ID'].isin(confident_list)]\n",
    "confident_0_all_df = confident_all_df[confident_all_df.prediction == 0]\n",
    "confident_1_all_df = confident_all_df[confident_all_df.prediction == 1]\n",
    "confident_0_avg = pd.DataFrame(confident_0_all_df.mean(axis=0)[1:-1]).T\n",
    "confident_1_avg = pd.DataFrame(confident_1_all_df.mean(axis=0)[1:-1]).T\n",
    "# get unconfident all 0 and 1 prediction averages\n",
    "unconfident_all_df =  all_df[all_df['ID'].isin(unconfident_list)]\n",
    "unconfident_0_all_df = unconfident_all_df[unconfident_all_df.prediction == 0]\n",
    "unconfident_1_all_df = unconfident_all_df[unconfident_all_df.prediction == 1]\n",
    "unconfident_0_avg = pd.DataFrame(unconfident_0_all_df.mean(axis=0)[1:-1]).T\n",
    "unconfident_1_avg = pd.DataFrame(unconfident_1_all_df.mean(axis=0)[1:-1]).T\n",
    "\n",
    "# fill confident additional data nan values with averages\n",
    "confident_additional_df = additional_df[additional_df['ID'].isin(confident_list)].copy()\n",
    "confident_0_additional_df = confident_additional_df[confident_additional_df.prediction == 0]\n",
    "confident_1_additional_df = confident_additional_df[confident_additional_df.prediction == 1]\n",
    "confident_0_additional_df = confident_0_additional_df.fillna(value=confident_0_avg.iloc[0])\n",
    "confident_1_additional_df = confident_1_additional_df.fillna(value=confident_1_avg.iloc[0])\n",
    "# fill unconfident additional data nan values with averages\n",
    "unconfident_additional_df = additional_df[additional_df['ID'].isin(unconfident_list)].copy()\n",
    "unconfident_0_additional_df = unconfident_additional_df[unconfident_additional_df.prediction == 0]\n",
    "unconfident_1_additional_df = unconfident_additional_df[unconfident_additional_df.prediction == 1]\n",
    "unconfident_0_additional_df = unconfident_0_additional_df.fillna(value=unconfident_0_avg.iloc[0])\n",
    "unconfident_1_additional_df = unconfident_1_additional_df.fillna(value=unconfident_1_avg.iloc[0])\n",
    "\n",
    "# update confident additional dataframe with new confident 0 and 1 values (filled nan values)\n",
    "confident_additional_df.update(confident_0_additional_df)\n",
    "confident_additional_df.update(confident_1_additional_df)\n",
    "# update unconfident additional dataframe with new unconfident 0 and 1 values (filled nan values)\n",
    "unconfident_additional_df.update(unconfident_0_additional_df)\n",
    "unconfident_additional_df.update(unconfident_1_additional_df)\n",
    "\n",
    "# update main additional dataframe with new confident and unconfident values \n",
    "additional_df.update(confident_additional_df)\n",
    "additional_df.update(unconfident_additional_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-create main dataframe with filled nan values\n",
    "all_df = pd.concat([train_df,additional_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true training and testing data\n",
    "raw_train_X = pd.DataFrame(all_df.drop(['ID', 'prediction'], axis=1))\n",
    "raw_train_y = pd.DataFrame(all_df['prediction'])\n",
    "raw_test_X = pd.DataFrame(test_df.drop(['ID'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits dataframe into feature sets\n",
    "def split_features(df):\n",
    "    CNN_features = pd.DataFrame(df[col] for col in df if 'CNN' in col).T\n",
    "    GIST_features = pd.DataFrame(df[col] for col in df if 'GIST' in col).T\n",
    "    return CNN_features, GIST_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces IDs for 20% of the data chosen randomly\n",
    "count = 0\n",
    "rand_rows = []\n",
    "while count <= len(raw_train_X)*0.2:\n",
    "    r = random.randint(0, len(raw_train_X)-1)\n",
    "    if(not r in rand_rows): #ensure value not already in array\n",
    "        rand_rows.append(r)\n",
    "        count+=1 #only increase if new value found\n",
    "rand_rows.sort() #visual representation only\n",
    "\n",
    "# split training data into its own training and testing data to test accuracy\n",
    "train_train_X  = pd.DataFrame(all_df[~all_df['ID'].isin([rn+1 for rn in rand_rows])].drop(['ID'], axis=1)) #75% of the data randomly selected for training\n",
    "train_train_y  = pd.DataFrame(train_train_X['prediction']) #80% of the predictions for training\n",
    "train_train_X = train_train_X.drop(['prediction'], axis=1)\n",
    "\n",
    "test_train_X   = pd.DataFrame(all_df[all_df['ID'].isin([rn+1 for rn in rand_rows])].drop(['ID'], axis=1)) #25% of the data randomly selected for testing\n",
    "test_train_y   = pd.DataFrame(test_train_X['prediction']) #20% of the preditions to test accuracy\n",
    "test_train_X = test_train_X.drop(['prediction'], axis=1)\n",
    "\n",
    "# split the featuresets of each for preprocessing\n",
    "train_X_CNN, train_X_GIST = split_features(train_train_X)\n",
    "test_X_CNN, test_X_GIST = split_features(test_train_X)\n",
    "raw_train_X_CNN, raw_train_X_GIST = split_features(raw_train_X)\n",
    "raw_test_X_CNN, raw_test_X_GIST = split_features(raw_test_X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " raw_train_X split  =      train_X_CNN | train_X_GIST\n",
    " raw_train_y split  =       test_X_CNN | test_X_GIST\n",
    " raw_train_X split  =  raw_train_X_CNN | raw_train_X_GIST\n",
    " raw_test_X  split  =   raw_test_X_CNN | raw_test_X_GIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNNs</th>\n",
       "      <th>CNNs.1</th>\n",
       "      <th>CNNs.2</th>\n",
       "      <th>CNNs.3</th>\n",
       "      <th>CNNs.4</th>\n",
       "      <th>CNNs.5</th>\n",
       "      <th>CNNs.6</th>\n",
       "      <th>CNNs.7</th>\n",
       "      <th>CNNs.8</th>\n",
       "      <th>CNNs.9</th>\n",
       "      <th>...</th>\n",
       "      <th>CNNs.4086</th>\n",
       "      <th>CNNs.4087</th>\n",
       "      <th>CNNs.4088</th>\n",
       "      <th>CNNs.4089</th>\n",
       "      <th>CNNs.4090</th>\n",
       "      <th>CNNs.4091</th>\n",
       "      <th>CNNs.4092</th>\n",
       "      <th>CNNs.4093</th>\n",
       "      <th>CNNs.4094</th>\n",
       "      <th>CNNs.4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.10963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15531</td>\n",
       "      <td>0.90697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50117</td>\n",
       "      <td>1.2053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46354</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.25908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30870</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.101230</td>\n",
       "      <td>0.090716</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CNNs   CNNs.1  CNNs.2  CNNs.3  CNNs.4   CNNs.5   CNNs.6  CNNs.7  CNNs.8  \\\n",
       "3  0.1349  0.10963     0.0     0.0     0.0  0.15531  0.90697     0.0     0.0   \n",
       "4  0.0000  0.25908     0.0     0.0     0.0  0.00000  0.00000     0.0     0.0   \n",
       "\n",
       "    CNNs.9    ...      CNNs.4086  CNNs.4087  CNNs.4088  CNNs.4089  CNNs.4090  \\\n",
       "3  0.05017    ...        0.50117     1.2053        0.0   0.018203        0.0   \n",
       "4  0.24830    ...        0.30870     0.0000        0.0   0.154070        0.0   \n",
       "\n",
       "   CNNs.4091  CNNs.4092  CNNs.4093  CNNs.4094  CNNs.4095  \n",
       "3        0.0    0.46354   0.034842   0.000000        0.0  \n",
       "4        0.0    0.00000   0.101230   0.090716        0.0  \n",
       "\n",
       "[2 rows x 4096 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018498</td>\n",
       "      <td>-0.312467</td>\n",
       "      <td>-0.296098</td>\n",
       "      <td>-0.365514</td>\n",
       "      <td>-0.350873</td>\n",
       "      <td>-0.101281</td>\n",
       "      <td>1.465069</td>\n",
       "      <td>-0.613027</td>\n",
       "      <td>-0.614757</td>\n",
       "      <td>-0.675600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417071</td>\n",
       "      <td>2.620707</td>\n",
       "      <td>-0.458957</td>\n",
       "      <td>-0.556035</td>\n",
       "      <td>-0.288868</td>\n",
       "      <td>-0.513946</td>\n",
       "      <td>0.121359</td>\n",
       "      <td>-0.340261</td>\n",
       "      <td>-0.529798</td>\n",
       "      <td>-0.313022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.499521</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>-0.296098</td>\n",
       "      <td>-0.365514</td>\n",
       "      <td>-0.350873</td>\n",
       "      <td>-0.538720</td>\n",
       "      <td>-0.743173</td>\n",
       "      <td>-0.613027</td>\n",
       "      <td>-0.614757</td>\n",
       "      <td>-0.272096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>-0.620012</td>\n",
       "      <td>-0.458957</td>\n",
       "      <td>-0.164007</td>\n",
       "      <td>-0.288868</td>\n",
       "      <td>-0.513946</td>\n",
       "      <td>-0.775200</td>\n",
       "      <td>-0.132216</td>\n",
       "      <td>-0.242797</td>\n",
       "      <td>-0.313022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.018498 -0.312467 -0.296098 -0.365514 -0.350873 -0.101281  1.465069   \n",
       "1 -0.499521  0.014733 -0.296098 -0.365514 -0.350873 -0.538720 -0.743173   \n",
       "\n",
       "       7         8         9       ...         4086      4087      4088  \\\n",
       "0 -0.613027 -0.614757 -0.675600    ...     0.417071  2.620707 -0.458957   \n",
       "1 -0.613027 -0.614757 -0.272096    ...     0.012707 -0.620012 -0.458957   \n",
       "\n",
       "       4089      4090      4091      4092      4093      4094      4095  \n",
       "0 -0.556035 -0.288868 -0.513946  0.121359 -0.340261 -0.529798 -0.313022  \n",
       "1 -0.164007 -0.288868 -0.513946 -0.775200 -0.132216 -0.242797 -0.313022  \n",
       "\n",
       "[2 rows x 4096 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "      <th>1170</th>\n",
       "      <th>1171</th>\n",
       "      <th>1172</th>\n",
       "      <th>1173</th>\n",
       "      <th>1174</th>\n",
       "      <th>1175</th>\n",
       "      <th>1176</th>\n",
       "      <th>1177</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.434089</td>\n",
       "      <td>-0.607244</td>\n",
       "      <td>19.977936</td>\n",
       "      <td>1.257532</td>\n",
       "      <td>7.033781</td>\n",
       "      <td>-19.318415</td>\n",
       "      <td>5.053727</td>\n",
       "      <td>8.468327</td>\n",
       "      <td>-13.054121</td>\n",
       "      <td>-10.514458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.841866</td>\n",
       "      <td>0.059119</td>\n",
       "      <td>-0.051674</td>\n",
       "      <td>0.541086</td>\n",
       "      <td>-0.814655</td>\n",
       "      <td>-0.334156</td>\n",
       "      <td>0.705097</td>\n",
       "      <td>-0.926820</td>\n",
       "      <td>-0.250778</td>\n",
       "      <td>0.578427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.244583</td>\n",
       "      <td>8.942845</td>\n",
       "      <td>-21.509884</td>\n",
       "      <td>7.222161</td>\n",
       "      <td>-5.649318</td>\n",
       "      <td>-4.680635</td>\n",
       "      <td>0.570581</td>\n",
       "      <td>-8.577338</td>\n",
       "      <td>3.402354</td>\n",
       "      <td>3.877572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037243</td>\n",
       "      <td>-0.367154</td>\n",
       "      <td>0.316129</td>\n",
       "      <td>0.493634</td>\n",
       "      <td>0.054989</td>\n",
       "      <td>-0.355752</td>\n",
       "      <td>-0.825594</td>\n",
       "      <td>-0.345571</td>\n",
       "      <td>0.140269</td>\n",
       "      <td>-0.478581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1          2         3         4          5         6     \\\n",
       "0  2.434089 -0.607244  19.977936  1.257532  7.033781 -19.318415  5.053727   \n",
       "1 -8.244583  8.942845 -21.509884  7.222161 -5.649318  -4.680635  0.570581   \n",
       "\n",
       "       7          8          9       ...         1168      1169      1170  \\\n",
       "0  8.468327 -13.054121 -10.514458    ...    -0.841866  0.059119 -0.051674   \n",
       "1 -8.577338   3.402354   3.877572    ...     0.037243 -0.367154  0.316129   \n",
       "\n",
       "       1171      1172      1173      1174      1175      1176      1177  \n",
       "0  0.541086 -0.814655 -0.334156  0.705097 -0.926820 -0.250778  0.578427  \n",
       "1  0.493634  0.054989 -0.355752 -0.825594 -0.345571  0.140269 -0.478581  \n",
       "\n",
       "[2 rows x 1178 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = train_X_CNN[:2]\n",
    "\n",
    "# Standardization\n",
    "sc_cnn=StandardScaler()\n",
    "train_X_CNN = pd.DataFrame(sc_cnn.fit_transform(train_X_CNN))\n",
    "test_X_CNN = pd.DataFrame(sc_cnn.transform(test_X_CNN))\n",
    "sc_gist=StandardScaler()\n",
    "train_X_GIST = pd.DataFrame(sc_gist.fit_transform(train_X_GIST))\n",
    "test_X_GIST = pd.DataFrame(sc_gist.transform(test_X_GIST))\n",
    "raw_sc_cnn=StandardScaler()\n",
    "raw_train_X_CNN = pd.DataFrame(sc_cnn.fit_transform(raw_train_X_CNN))\n",
    "raw_test_X_CNN = pd.DataFrame(sc_cnn.transform(raw_test_X_CNN))\n",
    "raw_sc_gist=StandardScaler()\n",
    "raw_train_X_GIST = pd.DataFrame(sc_cnn.fit_transform(raw_train_X_GIST))\n",
    "raw_test_X_GIST = pd.DataFrame(sc_cnn.transform(raw_test_X_GIST))\n",
    "\n",
    "t2 = train_X_CNN[:2]\n",
    "\n",
    "variance = 0.95\n",
    "\n",
    "# Principle Component Analysis - reduce dimensionality\n",
    "pca_cnn = PCA(variance)\n",
    "train_X_CNN = pd.DataFrame(pca_cnn.fit_transform(train_X_CNN))\n",
    "test_X_CNN = pd.DataFrame(pca_cnn.transform(test_X_CNN))\n",
    "pca_gist = PCA(variance)\n",
    "train_X_GIST = pd.DataFrame(pca_gist.fit_transform(train_X_GIST))\n",
    "test_X_GIST = pd.DataFrame(pca_gist.transform(test_X_GIST))\n",
    "raw_pca_cnn = PCA(variance)\n",
    "raw_train_X_CNN = pd.DataFrame(raw_pca_cnn.fit_transform(raw_train_X_CNN))\n",
    "raw_test_X_CNN = pd.DataFrame(raw_pca_cnn.transform(raw_test_X_CNN))\n",
    "raw_pca_gist = PCA(variance)\n",
    "raw_train_X_GIST = pd.DataFrame(raw_pca_gist.fit_transform(raw_train_X_GIST))\n",
    "raw_test_X_GIST = pd.DataFrame(raw_pca_gist.transform(raw_test_X_GIST))\n",
    "\n",
    "t3 = train_X_CNN[:2]\n",
    "\n",
    "display(t1, t2, t3)\n",
    "\n",
    "# Rejoin after standardisation and pca\n",
    "train_X = pd.concat([train_X_CNN.T, train_X_GIST.T]).T\n",
    "test_X = pd.concat([test_X_CNN.T, test_X_GIST.T]).T\n",
    "train_y = train_train_y\n",
    "test_y = test_train_y\n",
    "raw_train_X = pd.concat([raw_train_X_CNN.T, raw_train_X_GIST.T]).T\n",
    "raw_test_X = pd.concat([raw_test_X_CNN.T, raw_test_X_GIST.T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2071, 1472)\n",
      "(2071, 1)\n",
      "(519, 1472)\n",
      "(519, 1)\n",
      "(2818, 1665)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n",
    "print(raw_test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "3         1.0\n",
       "4         1.0\n",
       "6         1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {}\n",
    "for i in range(0, len(train_y)):\n",
    "    if int(train_y.iloc[i]) == 0:\n",
    "        class_weight[i] = {0:confidence[i], 1:1-confidence[i]}\n",
    "    else:\n",
    "        class_weight[i] = {0:1-confidence[i], 1:confidence[i]}\n",
    "#print(confidence[:5])\n",
    "#print(class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option1: Train model on training split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create function for MLP classifier\n",
    "def create_model(neurons1, neurons2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, input_dim=len(train_X.iloc[0]), activation='sigmoid'))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "    return model\n",
    "    #model.summary()\n",
    "\n",
    "# create keras classifier\n",
    "estimator = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs = [10]\n",
    "batch_size = [25]\n",
    "neurons1 = [64]\n",
    "neurons2 = [64]\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size, neurons1=neurons1, neurons2=neurons2)\n",
    "grid = GridSearchCV(estimator=estimator, param_grid = param_grid, n_jobs=1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_result = grid.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid.score(test_X, test_y)*100"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prediction = grid.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option2: Train model on raw training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for MLP classifier\n",
    "def create_model(neurons1, neurons2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, input_dim=len(raw_train_X.iloc[0]), activation='sigmoid'))\n",
    "    model.add(Dense(neurons2, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "    return model\n",
    "    #model.summary()\n",
    "\n",
    "# create keras classifier\n",
    "estimator = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [10]\n",
    "batch_size = [25]\n",
    "neurons1 = [64]\n",
    "neurons2 = [64]\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size, neurons1=neurons1, neurons2=neurons2)\n",
    "grid = GridSearchCV(estimator=estimator, param_grid = param_grid, n_jobs=1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(raw_train_X, raw_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.800000 using {'batch_size': 25, 'epochs': 10, 'neurons1': 64, 'neurons2': 64}\n",
      "0.800000 (0.007593) with: {'batch_size': 25, 'epochs': 10, 'neurons1': 64, 'neurons2': 64}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = grid.predict(raw_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  prediction\n",
       "0   1           1\n",
       "1   2           0\n",
       "2   3           0\n",
       "3   4           0\n",
       "4   5           0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(test_df['ID'])\n",
    "submission['prediction'] = [int(x[0]) for x in prediction]\n",
    "submission[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv('outputpredictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle results: CameL / cl497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
